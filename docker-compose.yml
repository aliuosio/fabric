services:

  ollama:
    container_name: ${NAMESPACE}_ollama
    image: ollama/ollama:latest
    pull_policy: always
    restart: unless-stopped
    env_file:
      - ./.env
    extra_hosts:
      - "host.docker.internal:host-gateway"
    tty: true
    init: true
    privileged: true
    volumes:
      - ~/.ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${OLLAMA_GPU_DRIVER-nvidia}
              count: 1
              capabilities:
                - gpu

  fabric:
    # build:
    #  context: ./.docker/fabric
    #  args:
    #    GO_IMAGE_VERSION: ${GO_IMAGE_VERSION}
    pull_policy: always
    container_name: ${NAMESPACE}_fabric
    image: osioaliu/fabric:latest
    env_file:
      - .env
    ports:
      - "9090:8080"
    working_dir: /go/bin
    volumes:
      - ./.env:/root/.config/fabric/.env
      - ~/fabric:/go/bin/output
    command: >
      /bin/bash -c "
        source /root/.bashrc &&
        fabric --serve
      "

  searxng:
    image: searxng/searxng:${SEARXNG_VERSION}
    container_name: ${NAMESPACE}_searxng
    pull_policy: always
    volumes:
      - ./.docker/searxng/settings.yml:/etc/searxng/settings.yml
    env_file:
      - .env
    expose:
      - 8080
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/healthz"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 15s